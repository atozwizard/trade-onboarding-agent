# [FIX] 기본 채팅 에이전트(DefaultChatAgent) 고도화 보고서

## 1. 개요 (Overview)
기존의 `DefaultChatAgent`는 정규표현식(Regex) 기반의 단순 매칭 방식으로 작동하여, 정해진 패턴 외의 질문이나 시스템 내부 지식에 대한 문의에 자연스럽게 대응하지 못하는 한계가 있었습니다. 이를 해결하기 위해 **LLM(Solar Pro) 기반의 자연어 대화 모델**로 전환하고, 시스템의 핵심 로직인 리스크 관리 기준을 학습시켜 지식 제공 능력을 강화했습니다.

## 2. 기획 의도 및 설계 (Design Intent & Architecture)

### 2.1 기획 의도
*   **자연스러운 사용자 경험(UX)**: 딱딱한 템플릿 응답이 아닌, 실제 사람과 대화하는 듯한 유연한 인터랙션 제공.
*   **지식 가이드 역할 수행**: 사용자가 서비스 이용 중 궁금해할 수 있는 '영향도', '가능성', '리스크 점수' 등의 산정 기준을 언제든 설명할 수 있는 도우미 역할 부여.
*   **범용성 확보**: 무역 도메인 외의 일상적인 대화 상황에서도 적절히 응대하며 플랫폼 기능으로 자연스럽게 유도.

### 2.2 시스템 설계
*   **LLM 엔진**: Upstage Solar Pro 모델을 사용하여 고도의 문맥 이해 및 응답 생성.
*   **프롬프트 엔지니어링**: `default_chat_prompt.txt`를 통해 리스크 관리 시스템의 5대 평가 항목 및 점수 체계(1-25점), 등급 기준(Low-Critical)을 명시적으로 주입.
*   **상태 유지**: 대화 이력(Conversation History)을 LLM 컨텍스트에 포함시켜 대화의 맥락이 끊기지 않도록 함.

## 3. 워크플로 (Workflow)

1.  **입력 수신**: Orchestrator가 사용자 의도를 분석하여 `default_chat`으로 라우팅하거나, 다른 에이전트가 처리할 수 없는 요청인 경우 해당 에이전트를 호출합니다.
2.  **컨텍스트 준비**:
    *   시스템 프롬프트 로드 (리스크 관리 기준 포함).
    *   최근 10회 이내의 대화 이력을 LLM용 메시지 포맷으로 변환.
3.  **LLM 추론**: Solar Pro 모델이 페르소나와 시스템 지식을 바탕으로 자연어 응답을 생성합니다.
4.  **응답 반환**: 생성된 메시지를 플랫폼 표준 응답 형식으로 변환하여 메타데이터와 함께 반환합니다.

## 4. 주요 수정 사양
*   **파일 수정**: `backend/agents/default_chat/default_chat_agent.py` (로직 전면 개편)
*   **신규 파일**: `backend/prompts/default_chat_prompt.txt` (지식 베이스 구축)
*   **기능 추가**: 리스크 점수 산정 방식(Impact x Likelihood) 및 수준별 기준에 대한 자연어 답변 기능.

## 5. 검증 결과
*   **인사 응대**: "안녕하세요! 무역 업무 지원을 위한 스마트 지식 가이드입니다..." 등 자연스러운 환영 멘트 확인.
*   **지식 질의**: "리스크 15점이면 위험해?" 질문에 대해 "15점은 'Critical(치명적)' 수준으로 즉각적인 전사적 대응이 필요한 단계입니다"라고 정확히 답변 확인.


수행 작업 내역
LLM 엔진 도입: 하드코딩된 Regex 응답 방식을 제거하고, Upstage Solar Pro를 사용하여 자연스러운 대화가 가능하도록 개편했습니다.
지식 베이스 구축 (
default_chat_prompt.txt
):
5대 평가 항목: 재정적 손실, 일정 지연, 관계 리스크, 규제 준수, 내부 비난 리스크.
점수 산정 방식: 영향도(1-5) × 발생 가능성(1-5) = 리스크 점수(1-25).
등급 기준: 15점 이상(Critical), 10~14점(High) 등 시스템 내부 기준을 명시적으로 학습시켰습니다.
대화 맥락 유지: 이전 대화 이력을 참고하여 답변을 생성하도록 로직을 수정했습니다.
문서화: 기획 의도와 설계 방향을 담은 **
docs/yyk/fix/fix_chatagent.md
**를 생성했습니다.

---

## 6. 협업형 대화 모드 (LLM Interaction Mode) 고도화

### 6.1 기획 의도
기존 시스템은 정보가 충분히 수집되면 즉시 완성된 보고서를 출력했습니다. 이는 사용자가 AI의 분석 과정을 신뢰하거나 개입할 기회를 차단하며, 일방적인 결과 통보처럼 느껴지는 결함이 있었습니다. 이를 해결하기 위해 **"사용자 승인 기반의 협업형 대화 프로세스"**를 도입했습니다.

### 6.2 설계 및 제약 사항
*   **보고서 생성 자동화 금지**: 정보가 충분(`sufficient`)하더라도 사용자의 명시적 요청이나 제안에 대한 긍정 응답 없이는 리포트를 생성하지 않습니다.
*   **중간 추론 공유**: 리포트 출력 전, 현재까지 파악된 리스크의 핵심을 상사처럼 짧게 언급하여 AI의 판단 근거를 사용자에게 투명하게 공개합니다.
*   **상태 기반 게이트킹**: `report_requested` 상태 변수를 도입하여 워크플로가 최종 분석 노드로 진입하는 것을 제어합니다.

### 6.3 워크플로 (Workflow)
1.  **정보 수집 및 평가**: `assess_conversation_progress_node`에서 정보를 추출하고 분석 가능 여부를 판단합니다.
2.  **협업 포인트 발생**: 
    *   정보가 충분할 경우: RAG 검색 결과와 추출된 데이터를 바탕으로 "중간 추론"을 제공하며 "보고서로 정리할까요?"라고 질문합니다.
    *   사용자 반응 대기: 이 단계에서 시스템은 대화 모드를 유지합니다.
3.  **보고서 출력 승인**:
    *   사용자가 "응", "OK" 등 긍정하거나 "보고서로 뽑아줘"라고 명시적으로 요청하면 `report_requested`가 `True`로 전환됩니다.
4.  **최종 보고서 생성**: 승인이 완료된 경우에만 `perform_full_analysis_node`로 진입하여 정식 리포트를 출력합니다.

### 6.4 주요 수정 사항
*   **`nodes.py`**: `CONVERSATION_ASSESSMENT_PROMPT`를 협업 지침에 맞게 전면 개편하고, `report_requested` 판별 로직을 추가했습니다.
*   **`state.py`**: `RiskManagingGraphState`에 `report_requested` 필드를 추가했습니다.
*   **`riskmanaging_prompt.txt`**: 시스템 프롬프트에 **LLM Interaction Mode** 강제 지침을 삽입하여 일관된 협업 톤을 유지하게 했습니다.