A. 데이터/시나리오 확장 작업

시나리오 엔티티 채우기

현재 entities: {} 비어있음 → 금액/통화/국가/은행/SWIFT/인코텀/기한/문서필드 등을 최소 3~8개 채우는 규칙 추가

목적: LLM이 “상황”을 더 정확히 잡고 리스크를 구체화

케이스 다양화(11 → 50)

정상/엣지/예외 케이스 비율(60/20/10/10)로 확장

최소: payment, documentation, customs, incoterms, communication 5개 축 × 각 10개

실수사례 데이터 스키마 고도화

현재: id/risk_type/feedback/loss

추가: root_cause, trigger_pattern, prevent_checklist, severity, common_wrong_action, recovery_action

목적: “사수급 코칭”을 데이터 기반으로 만들기

B. RAG 품질/근거(출처) 강화 (할루시네이션 방지 핵심)

VectorDB 문서 분리 전략

mistakes(사례) / internal_process(사내 절차) / document_errors(서류 필드 오류) / country_rules(국가별 규정) 컬렉션 분리

목적: 검색 정확도 + 근거 출처 명확화

Retrieval 정책 고정(룰)

상황(topic/doc_type)에 따라 컬렉션 선택 규칙 작성

예: payment → mistakes + internal_process, customs → country_rules + document_errors

목적: “의도에 맞는 검색” 강제

Evidence Sources 강제 출력

agent 출력 JSON의 evidence_sources에 retrieved doc id + score + snippet 강제

목적: “왜 그렇게 판단했는지”를 자동으로 남김

C. MistakePredictAgent 구현 작업 (스펙 준수)

출력 JSON 스키마 고정(필수필드 100%)

batch_runner_users 기준 REQUIRED_TOP/RS를 agent가 항상 만족하도록

누락 시: fallback(uncertain) + clarifying_questions

유저 프로필 반영 로직

preferred_style(블런트/체크리스트/코칭/간결)별 템플릿 분기

risk_tolerance가 low면 “즉시 중지/상신” 강하게, high면 “대안 제시” 중심

리스크 스코어링 기준 통일

impact/likelihood 산정 규칙을 최소 룰로 고정

예: payment 오류는 impact 기본 4, documentation mismatch 기본 3 등

목적: 케이스마다 점수 일관성

D. 자동 평가/테스트 체계 
Batch 평가 지표 업그레이드

지금: 필드+키워드

추가:

risk_factors 최소 2개

prevention_strategy 3레벨(개인/프로세스/시스템)

evidence_sources 존재 + retrieved id 포함

(가능하면) risk_type 예측이 expected_risk_type과 맞는지

Regression Test 고정

33 시나리오 + 5 유저 = 165 테스트를 CI에서 자동 실행

PASS 기준: 전체 PASS율/특정 중요 케이스 PASS 필수


import uuid
from typing import Dict, List

try:
    from langchain_chroma import Chroma
except Exception:
    from langchain.vectorstores import Chroma

from langchain_upstage import UpstageEmbeddings


class MistakePredictAgent:

    def __init__(self, persist_dir: str = "vector_db"):
        embeddings = UpstageEmbeddings()
        self.vs = Chroma(
            collection_name="mistakes",
            embedding_function=embeddings,
            persist_directory=persist_dir
        )

    # -----------------------------
    # 내부: 안전한 리스크 점수 계산
    # -----------------------------
    def _score(self, text: str) -> Dict:
        text = text.lower()

        impact = 3
        likelihood = 3

        if any(k in text for k in ["송금", "보험", "lc", "결제"]):
            impact = 5
        elif any(k in text for k in ["hs code", "통관", "인코텀"]):
            impact = 4

        if any(k in text for k in ["오타", "누락", "불일치"]):
            likelihood = 4

        total = impact * likelihood

        if total <= 5:
            level = "low"
        elif total <= 10:
            level = "medium"
        elif total <= 15:
            level = "high"
        else:
            level = "critical"

        return {
            "impact_score": impact,
            "likelihood_score": likelihood,
            "total_risk_score": total,
            "risk_level": level
        }

    # -----------------------------
    # RAG 검색
    # -----------------------------
    def _retrieve(self, query: str, k: int = 3):
        docs = self.vs.similarity_search_with_score(query, k=k)
        return docs

    # -----------------------------
    # 메인 분석 함수
    # -----------------------------
    def analyze(self, user_input: str, user_profile: Dict = None) -> Dict:

        analysis_id = str(uuid.uuid4())

        retrieved = self._retrieve(user_input)

        evidence_sources = []
        risk_factors = []

        for doc, score in retrieved:
            meta = doc.metadata or {}

            evidence_sources.append({
                "source_type": "vector_db",
                "reference_id": meta.get("id", "unknown"),
                "score": float(score),
                "snippet": doc.page_content[:120]
            })

            risk_factors.append({
                "risk_type": meta.get("risk_type", "unknown"),
                "description": doc.page_content.split("\n")[1] if "\n" in doc.page_content else doc.page_content,
                "category": "operational"
            })

        if len(risk_factors) == 0:
            risk_factors = [
                {"risk_type": "unknown", "description": "유사 사례 탐지 실패", "category": "unknown"},
                {"risk_type": "unknown", "description": "추가 확인 필요", "category": "unknown"},
            ]

        risk_scoring = self._score(user_input)

        loss_description = "통관 지연 또는 금전 손실 발생 가능"

        prevention_strategy = {
            "individual_level": [
                "핵심 필드 더블체크",
                "문서 간 값 비교 검토"
            ],
            "process_level": [
                "출항 전 사전 검토 절차 수행"
            ],
            "system_level": [
                "자동 검증 로직 적용"
            ]
        }

        return {
            "analysis_id": analysis_id,
            "input_summary": user_input,
            "risk_factors": risk_factors[:3],
            "risk_scoring": risk_scoring,
            "loss_description": loss_description,
            "prevention_strategy": prevention_strategy,
            "confidence_score": round(min(0.95, 0.6 + len(evidence_sources)*0.1), 2),
            "evidence_sources": evidence_sources
        }
