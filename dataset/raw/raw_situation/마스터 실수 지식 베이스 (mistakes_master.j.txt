제공해주신 use_case.md와 원본 파일들을 바탕으로, 실제 서비스 개발에 즉시 사용할 수 있도록 **통합 마스터 데이터셋(Master Dataset)**을 설계하고 생성해 드립니다.
가장 중요한 작업은 분산된 실수 상세 정보(message.txt)와 현장 피드백(가상사례 11)을 ID(M001~M020)를 기준으로 결합하는 것입니다.


1. 마스터 실수 지식 베이스 (mistakes_master.json)
이 데이터셋은 RAG의 검색 대상이자, AI 사수가 답변을 생성할 때 참조하는 핵심 지식입니다.
Schema:
id: 고유 식별자
risk_type: 리스크 명칭 (가상사례 데이터 기반)
supervisor_feedback: 사수의 직접적인 훈수 (가상사례 데이터 기반)
details: message.txt에서 가져온 상세 리스크 분석 데이터
code
JSON
[
  {
    "id": "M001",
    "risk_type": "이름 오타",
    "category": "BL_CHECK",
    "severity": "HIGH",
    "supervisor_feedback": "수하인 이름에 오타가 보입니다. 철자 하나만 틀려도 현지에서 물건을 못 찾고 재발행 비용이 발생합니다.",
    "description": "수하인(Consignee) 정보 입력 시 철자 오류",
    "expected_loss": "$500 ~ $1,500",
    "consequences": [
      "통관 지연 (평균 3-5일)",
      "BL amendment 비용 $150-300",
      "바이어 클레임 발생 가능"
    ],
    "prevention": [
      "계약서 원본과 글자 단위로 대조",
      "회사명은 공식 영문명 사용",
      "띄어쓰기, 대소문자까지 정확히 확인"
    ],
    "real_case": "2024년 1월, ABC사 케이스: 'CO., LTD' → 'CO, LTD' 오타로 통관 4일 지연"
  },
  {
    "id": "M005",
    "risk_type": "금액 불일치",
    "category": "CUSTOMS",
    "severity": "CRITICAL",
    "supervisor_feedback": "품목별 합계와 최종 금액이 맞지 않습니다. 계산 실수나 오타는 신뢰도를 크게 떨어뜨립니다. 다시 계산해 보세요.",
    "description": "Commercial Invoice 금액 허위 기재 또는 계산 착오",
    "expected_loss": "$45,000 + 과태료",
    "consequences": [
      "밀수 혐의 조사",
      "통관 보류 및 가산세 부과",
      "향후 수입 불이익"
    ],
    "prevention": [
      "Under Invoice 절대 금지",
      "계약서, 송금 내역과 일치 확인",
      "외화 환율 적용 시 주의"
    ]
  },
  {
    "id": "M010",
    "risk_type": "송금 정보 오류",
    "category": "PAYMENT",
    "severity": "CRITICAL",
    "supervisor_feedback": "은행명(영국)과 SWIFT 코드(한국)의 국가 정보가 다릅니다. 이대로 송금하면 자금 회수가 불가능할 수 있습니다!",
    "description": "수취인 계좌번호, SWIFT Code 오기재",
    "expected_loss": "송금액 전액 (최대 $10만+)",
    "consequences": [
      "대금 오송금 및 자금 회수 불능",
      "추가 수수료 발생",
      "공급망 거래 중단"
    ],
    "prevention": [
      "Beneficiary Bank SWIFT Code 재검증",
      "소액 테스트 송금 프로세스 도입"
    ]
  }
  /* ... 나머지 M001~M020 데이터 동일 구조로 병합 ... */
]
2. 사용자 프로필 데이터셋 (users_master.json)
서비스 검증(Batch Test) 시 사용할 유저 세트입니다. 가장 최신 버전(0213 서비스 검증)을 기준으로 정리했습니다.
code
JSON
[
  {
    "user_id": "U01",
    "role_level": "junior",
    "experience_months": 1,
    "weak_topics": ["payment", "documentation"],
    "risk_tolerance": "low",
    "preferred_style": "coaching"
  },
  {
    "user_id": "U02",
    "role_level": "junior",
    "experience_months": 6,
    "weak_topics": ["customs"],
    "risk_tolerance": "low",
    "preferred_style": "checklist"
  },
  {
    "user_id": "U03",
    "role_level": "working",
    "experience_months": 24,
    "weak_topics": ["incoterms"],
    "risk_tolerance": "medium",
    "preferred_style": "concise"
  },
  {
    "user_id": "U04",
    "role_level": "senior",
    "experience_months": 60,
    "weak_topics": [],
    "risk_tolerance": "low",
    "preferred_style": "blunt"
  },
  {
    "user_id": "U05",
    "role_level": "sales",
    "experience_months": 36,
    "weak_topics": ["negotiation"],
    "risk_tolerance": "high",
    "preferred_style": "concise"
  }
]
3. [Python Script] 데이터 병합 자동화 도구
원본 파일들이 수정될 때마다 자동으로 마스터 JSON을 생성해주는 스크립트입니다. dataset/raw/raw_situation 폴더 내의 파일들을 읽어 병합합니다.
code
Python
import json
import csv
import io
from pathlib import Path

def build_master_dataset():
    raw_dir = Path("dataset/raw/raw_situation")
    
    # 1. message.txt (상세 정보) 로드
    message_data = json.loads((raw_dir / "message.txt").read_text(encoding="utf-8"))
    mistakes_dict = { m["id"]: m for m in message_data }
    
    # 2. 가상사례 11 (피드백/손실) 병합
    case_text = (raw_dir / "가상사례 11 (1).txt").read_text(encoding="utf-8")
    # CSV 부분 추출
    csv_part = case_text.split("id,risk_type,supervisor_feedback,expected_loss")[1].strip()
    reader = csv.DictReader(io.StringIO("id,risk_type,supervisor_feedback,expected_loss\n" + csv_part))
    
    for row in reader:
        mid = row['id'].strip()
        if mid in mistakes_dict:
            # 기존 상세 데이터에 현장 피드백 데이터 업데이트
            mistakes_dict[mid]["supervisor_feedback"] = row['supervisor_feedback'].strip().strip('"""')
            mistakes_dict[mid]["expected_loss_dynamic"] = row['expected_loss'].strip()

    # 3. 통합 마스터 저장
    master_path = Path("dataset/processed/mistakes_master.json")
    master_path.parent.mkdir(parents=True, exist_ok=True)
    master_path.write_text(json.dumps(list(mistakes_dict.values()), ensure_ascii=False, indent=2), encoding="utf-8")
    
    print(f"Master Dataset created at: {master_path}")

if __name__ == "__main__":
    build_master_dataset()
이 데이터셋으로 할 수 있는 일:
RAG 인덱싱: mistakes_master.json의 description과 supervisor_feedback을 임베딩하여 Vector DB에 넣으면, 사용자의 질문에 가장 적합한 "사수 피드백"을 찾아낼 수 있습니다.
페르소나 기반 답변: U02(Checklist 선호)가 질문하면 prevention 배열을 번호 매긴 리스트로 출력하고, U04(Blunt 선호)가 질문하면 supervisor_feedback 한 문장만 출력하도록 분기 로직을 짤 수 있습니다.
손실 예측: AI가 리스크를 탐지했을 때 expected_loss_dynamic 필드를 참조하여 "이 실수는 최대 $10만 이상의 손실을 초래할 수 있습니다"라고 구체적인 숫자를 제시할 수 있습니다.