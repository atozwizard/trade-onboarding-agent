# Trade Onboarding Agent — 슬라이드 텍스트 초안

> **폰트 가이드 (템플릿 기준 Noto Sans KR)**
> - 발표 제목(표지): Bold, 36pt
> - 섹션 번호/대제목: Bold, 28pt
> - 소제목(슬라이드 제목): Bold, 20pt
> - 본문: Regular, 16pt
> - 보조 설명/캡션: Regular, 12pt
> - 각주/출처: Regular, 6pt
> - 불렛 기호: ● (원형 통일)

---

## SLIDE 01 — 표지

**[발표 제목]** `Bold, 36pt`
```
Trade Onboarding Agent
채팅으로 시작하는 무역 실무 온보딩
```

**[발표자]** `Regular, 16pt`
```
팀원: 이성준 · 차세종 · 황지은 · 이영기
발표자: 이성준
```

**[하단]** `Regular, 12pt`
```
© 2026 Upstage Co., Ltd.   |   SeSAC AIPE Project
```

> 📌 권장 이미지: 항구·컨테이너 배경 이미지

---

## SLIDE 02 — Contents (목차)

**[제목]** `Bold, 28pt`
```
Contents
```

**[목차 항목]** `Bold, 20pt`
```
1. 팀 소개 및 주제
2. 서비스 기획 및 서비스 디자인
3. Agent Workflow 기획 및 구성
   — QuizAgent / EmailAgent / RiskManagingAgent
4. Agent Workflow 개발/평가 및 시연
```

---

## SLIDE 03 — 01. 팀 소개

**[섹션]** `Bold, 28pt` `배경 섹션 뱃지: 01`
```
팀 소개 및 주제
```

**[소제목]** `Bold, 20pt`
```
팀 소개 및 역할
```

**[본문 — 팀원 카드 4개]** `Regular, 16pt`
```
● 이성준   QuizAgent · EvalTool 개발
● 차세종   RiskManagingAgent 개발
● 황지은   EmailAgent 개발
● 이영기   프론트엔드 · RAG 파이프라인
```

**[보조]** `Regular, 12pt`
```
* 역할은 예시이며 발표 당일 수정 예정
```

> 📌 권장 도식: 4명 프로필 카드 2×2 격자 배치

---

## SLIDE 04 — 01. 문제 정의

**[소제목]** `Bold, 20pt`
```
왜 무역 신입사원 온보딩이 어려운가?
```

**[본문]** `Regular, 16pt`
```
● 무역 실무 용어·프로세스는 암기보다 반복 경험이 필요
● 기존 온보딩: 문서 중심 → 단방향 학습 → 낮은 몰입도
● 실수 한 번이 페널티·클레임·계약 분쟁으로 직결되는 고위험 도메인
● AI 코치가 대화하며 실시간 피드백을 주는 시스템 부재
```

**[핵심 메시지 강조 박스]** `Bold, 20pt`
```
"실무는 교과서가 아니라 대화로 배운다"
```

> 📌 권장 이미지: 문서 더미 vs 채팅 버블 Before/After 구도

---

## SLIDE 05 — 02. 서비스 개요 (기획 + 전체 흐름)

**[섹션]** `Bold, 28pt` `배경 섹션 뱃지: 02`
```
서비스 기획 및 서비스 디자인
```

**[소제목]** `Bold, 20pt`
```
서비스 개요 및 전체 흐름
```

**[본문 좌]** `Regular, 16pt`
```
● 타겟: 무역회사 신입사원 (1~2년차)
● 핵심 학습 영역
    ○ Incoterms / 결제 조건 (L/C, T/T)
    ○ 무역 이메일 작성 및 검토
    ○ 공급망 리스크 대응
● 데이터 규모
    ○ 17개 JSON / 782 ingestable records
    ○ ICC 무역용어집 284개
```

**[본문 우 — 시스템 흐름 다이어그램]** `캡션 Regular, 12pt`
```
[📌 기획서 graph LR 다이어그램 캡처 삽입]

👤 신입사원 → 💬 React UI
  → 🎯 Orchestrator (자동 라우팅)
    → 📝 QuizAgent
    → ✉️  EmailAgent
    → 🚨 RiskManagingAgent
```

---

## SLIDE 06 — 03. Orchestrator + 시스템 구조

**[섹션]** `Bold, 28pt` `배경 섹션 뱃지: 03`
```
Agent Workflow 기획 및 구성
```

**[소제목]** `Bold, 20pt`
```
Orchestrator 중심 설계 — LLM만으론 부족한 이유
```

**[본문 좌]** `Regular, 16pt`
```
● LLM만으로 풀 수 없는 문제
    ○ 무역 도메인 특화 지식 → RAG 필요
    ○ 퀴즈 품질 보장 → EvalTool 검증 필요
    ○ 리스크 분석 → 멀티턴 + 구조화 보고서

● Orchestrator 라우팅 우선순위
    ① active_agent 유지 (멀티턴 진행 중)
    ② context.mode 명시 (프론트 오버라이드)
    ③ LLM 인텐트 분류 (solar-pro2)
    ④ DefaultChatAgent (폴백)
```

**[본문 우 — 다이어그램]**
```
[📌 기획서 Orchestrator flowchart TD 캡처 삽입]
```

---

## SLIDE 07 — 03. RAG + Tool 구성

**[소제목]** `Bold, 20pt`
```
RAG 파이프라인 및 Tool 활용
```

**[본문]** `Regular, 16pt`
```
● RAG
    ○ ChromaDB (cosine 유사도) + Upstage Solar Embedding (1024차원)
    ○ 17개 JSON → 782 ingestable records 임베딩
    ○ ICC PDF → Upstage Document Parse API(OCR) → 283개 용어 추출

● 내부 Tool
    ○ EvalTool: 퀴즈 5항목 품질 자동 검증
    ○ TradeTermValidator: 무역 용어 정확성 검증
    ○ UnitValidator: 단위 일관성 검증 (MT/CBM/TEU)
```

**[우측 — 파이프라인 다이어그램]**
```
[📌 기획서 데이터 파이프라인 flowchart LR 캡처 삽입]
```

---

## SLIDE 08 — 03. QuizAgent — 핵심 기능 + 목표 UX

**[소제목]** `Bold, 20pt`
```
📝 QuizAgent — RAG 기반 퀴즈 학습
```

**[본문 — 핵심 기능]** `Regular, 16pt`
```
● 핵심 기능
    ○ ChromaDB에서 실제 무역 용어 검색 → 4지선다 퀴즈 5문제 생성
    ○ 두 가지 출제 방향: 용어→설명 / 설명→용어
    ○ 난이도 선택: easy / medium / hard / 혼합(기본값)
    ○ EvalTool이 문제·정답·오답·인덱스·해설 5항목 자동 검증
    ○ 불합격 문제: 최대 2회 재시도 → 소진 시 다른 용어로 대체 생성
    ○ 정답 해설은 답 제출 후에만 공개 (학습 효과 극대화)

● 목표 UX
    ○ 채팅창에 "FOB 퀴즈 풀고 싶어요" 한 문장으로 즉시 시작
    ○ 번호 입력만으로 답변 → 정오답 + 해설 즉시 제공
    ○ 어려운 용어일수록 RAG 유사 용어를 오답으로 배치해 학습 밀도 ↑
```

> 📌 권장 이미지: 퀴즈 생성 + 채점 화면 스크린샷

---

## SLIDE 09 — 03. QuizAgent — 확장성 아이디어

**[소제목]** `Bold, 20pt`
```
📝 QuizAgent — 확장 가능성
```

**[본문]** `Regular, 16pt`
```
● 개인화 학습 이력
    ○ 회원 DB 구축 → 개인별 오답 히스토리 저장
    ○ 오답 문제만 모아 "복습 모드" 자동 생성
    ○ 주제별 누적 점수 → 취약 영역 자동 파악

● HR 인증 시스템
    ○ 사내 HR이 정한 합격 기준(점수·주제)을 충족하면 수료증 자동 발급
    ○ 주제별 인증 가능: Incoterms 인증 / 결제 조건 인증 / 리스크 관리 인증
    ○ 신입사원 온보딩 완료 지표로 활용 가능
```

---

## SLIDE 10 — 03. EmailAgent — 기능 + 확장성

**[소제목]** `Bold, 20pt`
```
✉️ EmailAgent — 초안 작성부터 검토까지 한 흐름
```

**[본문 — 핵심 기능 + UX]** `Regular, 16pt`
```
● 핵심 기능 (한 흐름: 초안 → 수정 → 검토 → 예외 처리)
    ○ Draft Mode: "미국 바이어 제안 메일 작성" → 거래 조건 반영 초안 생성
    ○ 수정: "영어로 더 공손하게 바꿔줘" → 같은 맥락에서 즉시 반영
    ○ Review Mode: 리스크 탐지 + 톤 분석 + 무역 용어 검증 + 단위 검증
    ○ 예외 처리: 본문 없이 검토 요청 시 추가 정보 먼저 요청 (오검토 방지)

● 목표 UX
    ○ 짧은 자연어 요청 한 줄로 전체 흐름 처리
    ○ FOV→FOB 오류처럼 실무 실수를 자동 탐지해 즉시 교정

● 확장성 아이디어
    ○ Gmail MCP 연결 → 검토 완료 후 실제 발송까지 연결
    ○ 거래처별 이메일 히스토리 저장 → 문체·협상 패턴 학습
```

> 📌 권장 이미지: 이메일 검토 결과 화면 스크린샷 (FOV→FOB 오류 탐지)

---

## SLIDE 11 — 03. RiskManagingAgent — 기능 + 확장성

**[소제목]** `Bold, 20pt`
```
🚨 RiskManagingAgent — 실무 선배처럼 리스크를 분석한다
```

**[본문 — 핵심 기능 + UX]** `Regular, 16pt`
```
● 핵심 기능
    ○ 협업형 멀티턴 분석: 계약금·패널티 등 부족한 정보를 역으로 질문하며 수집
    ○ 교육적 페르소나: 리스크 산출 기준(영향도×발생 가능성)을 친절히 설명
    ○ RAG 기반 유사 클레임 사례 검색 → 과거 대응 전략 포함
    ○ 최종 JSON 보고서: 리스크 점수 + 단기/장기 예방 전략 구조화 출력

● 목표 UX
    ○ "선적 지연" 한 마디로 분석 시작 → 대화로 정보 채움 → 보고서 생성
    ○ 자동 응답기가 아닌 '실무 현장의 선배' 역할

● 확장성 아이디어
    ○ 실시간 글로벌 리스크 감지: 해외 뉴스 API + 항만 혼잡도 데이터 연동
      → 대화 중이 아니어도 선제적 리스크 경고 트리거
    ○ 사내 ERP 연동: 계약 금액·패널티 조항 자동 조회 → 정보 입력 불필요
```

> 📌 권장 이미지: 리스크 보고서 JSON 시각화 스크린샷

---

## SLIDE 12 — 04. 기술 스택 + 역할 분담

**[섹션]** `Bold, 28pt` `배경 섹션 뱃지: 04`
```
Agent Workflow 개발/평가 및 시연
```

**[소제목]** `Bold, 20pt`
```
기술 스택 및 역할 분담
```

**[기술 스택 표]** `Regular, 14pt`
```
레이어        │ 기술                         │ 역할
─────────────┼──────────────────────────────┼─────────────────────
패키지 관리   │ uv                           │ Python 패키지 매니저
프론트엔드   │ React 18 + Vite 5            │ 채팅 UI
백엔드        │ FastAPI + Python 3.11        │ RESTful API 서버
LLM          │ Upstage Solar (solar-pro2)   │ 자연어 이해/생성
임베딩        │ Upstage Solar Embedding      │ 문서 벡터화 (1024차원)
벡터 DB      │ ChromaDB                     │ RAG 문서 검색
트레이싱      │ LangSmith                    │ 에이전트 실행 디버깅
```

**[역할 분담]** `Regular, 16pt`
```
● 이성준  — QuizAgent · EvalTool 개발
● 차세종  — RiskManagingAgent 개발
● 황지은  — EmailAgent 개발
● 이영기  — 프론트엔드 · RAG 파이프라인
```

---

## SLIDE 13 — 04. 평가 방법 (EvalTool)

**[소제목]** `Bold, 20pt`
```
Agent Workflow 평가 — EvalTool 품질 검증
```

**[본문]** `Regular, 16pt`
```
● EvalTool 검증 항목 (5개)
    ○ 문제: RAG 원본 반영 여부
    ○ 정답 선택지: 원본 데이터 일치
    ○ 오답 선택지: 실존 용어 기반 (완전 허구 배제)
    ○ 정답 인덱스: RAG 재검색으로 재확인
    ○ 해설: 원본 내용 부합 여부

● 재시도 루프 (MAX_RETRY = 2)
    ① is_valid = false → issues 피드백 포함 재생성
    ② 2회 소진 → 다른 용어로 대체 생성
    ③ 합격 5문제 달성 시 즉시 종료

● 예상 품질 지표
    ○ 퀴즈 합격률 ~90%  |  무역 용어 검증 ~90%  |  단위 검증 ~95%
```

---

## SLIDE 14 — 04. 데모

**[소제목]** `Bold, 20pt`
```
서비스 데모
```

**[3분할 스크린샷 레이아웃]**
```
┌──────────────────┬──────────────────┬──────────────────┐
│   📝 퀴즈 학습   │  ✉️ 이메일 검토  │ 🚨 리스크 분석   │
│                  │                  │                  │
│  [스크린샷 1]    │  [스크린샷 2]    │  [스크린샷 3]    │
│  퀴즈 5문제      │  FOV→FOB 오류    │  JSON 보고서     │
│  생성 화면       │  탐지 화면       │  시각화 화면     │
└──────────────────┴──────────────────┴──────────────────┘
```

**[영상]** `Regular, 12pt`
```
▶ 전체 데모 영상: [ 영상 파일 삽입 또는 URL ]
```

---

## SLIDE 15 — 마무리 + Q&A

**[소제목]** `Bold, 20pt`
```
결론 및 향후 발전 방향
```

**[본문 좌 — 구현 성과]** `Regular, 16pt`
```
● 구현 성과
    ○ RAG 기반 3개 전문 에이전트 완성
    ○ EvalTool 자동 품질 검증 루프
    ○ 멀티턴 리스크 분석 + JSON 보고서
    ○ 782개 무역 지식 ChromaDB 구축
```

**[본문 우 — 향후 방향]** `Regular, 16pt`
```
● 향후 발전 방향
    ○ 개인별 오답 히스토리 + HR 인증 시스템
    ○ Gmail MCP 연결 → 이메일 실제 발송
    ○ 실시간 리스크 감지 (뉴스 API + 항만 데이터)
    ○ 사내 ERP 연동 → 계약 정보 자동 조회
    ○ Redis 세션 영속성 + 계약서 PDF 분석
```

**[하단 중앙 Q&A]** `Bold, 36pt`
```
Q & A   /   감사합니다.
```

---

## 🎙️ 7분 발표 스크립트

### SLIDE 01 — 표지 (0:00~0:10)
> "안녕하세요. 저희 팀은 무역회사 신입사원을 위한 AI 온보딩 챗봇, Trade Onboarding Agent를 개발했습니다."

---

### SLIDE 02 — Contents (0:10~0:15)
> *(목차 간단히 짚고 넘어감 — 말 없이 3초 보여줘도 됨)*

---

### SLIDE 03 — 팀 소개 (0:15~0:45)
> "팀원은 총 4명입니다. 이성준이 QuizAgent와 EvalTool, 차세종이 RiskManagingAgent, 황지은이 EmailAgent, 이영기가 프론트엔드와 RAG 파이프라인을 담당했습니다."

---

### SLIDE 04 — 문제 정의 (0:45~1:25)
> "저희가 주목한 문제는 무역 신입사원 온보딩입니다. 무역 업무는 Incoterms, 결제 조건, 협상 이메일 등 도메인 특화 지식이 많고, 실수 한 번이 클레임·계약 분쟁으로 이어지는 고위험 환경입니다. 기존 문서 중심 교육으로는 실무 감각을 키우기 어렵습니다. 그래서 저희는 '실무는 교과서가 아니라 대화로 배운다'는 철학으로 채팅 기반 AI 온보딩을 만들었습니다."

---

### SLIDE 05 — 서비스 개요 (1:25~1:55)
> "서비스 흐름입니다. 사용자가 채팅창에 메시지를 입력하면 Orchestrator가 의도를 자동 분류해 세 전문 에이전트 중 하나로 라우팅합니다. 타겟은 무역회사 1~2년차이며, ICC 무역용어집 284개를 포함해 782개 레코드를 ChromaDB에 구축했습니다."

---

### SLIDE 06 — Orchestrator (1:55~2:25)
> "LLM만으로 부족한 지점이 세 가지였습니다. 첫째 도메인 특화 지식은 RAG로, 둘째 퀴즈 품질 보장은 EvalTool 검증 루프로, 셋째 리스크 분석은 멀티턴 대화 + 구조화 보고서로 해결했습니다. Orchestrator는 활성 에이전트 유지→명시 모드→LLM 분류→폴백 순으로 라우팅합니다."

---

### SLIDE 07 — RAG + Tool (2:25~2:50)
> "RAG는 Upstage Solar Embedding으로 782개 레코드를 ChromaDB에 벡터화했고, ICC 무역용어집 PDF는 Upstage Document Parse API로 OCR 처리해 283개 용어를 추출했습니다. 내부 Tool로는 EvalTool, TradeTermValidator, UnitValidator를 구현했습니다."

---

### SLIDE 08 — QuizAgent 기능 + UX (2:50~3:30)
> "QuizAgent입니다. RAG로 검색한 실제 무역 용어로 4지선다 퀴즈 5문제를 생성합니다. 출제 방향은 용어→설명, 설명→용어 두 가지이며 난이도도 선택할 수 있습니다. EvalTool이 문제·정답·오답·인덱스·해설 5항목을 자동 검증하고, 불합격 문제는 피드백 포함 재생성합니다. UX 핵심은 '채팅 한 줄로 시작, 번호 입력으로 답변, 즉시 해설 제공'입니다. 특히 유사 용어를 오답으로 배치해 혼동하기 쉬운 용어끼리 비교하게 됩니다."

---

### SLIDE 09 — QuizAgent 확장성 (3:30~3:45)
> "확장성으로는 개인별 오답 히스토리와 복습 모드, 그리고 HR이 정한 기준을 충족하면 주제별 수료증을 발급하는 인증 시스템을 구상하고 있습니다. 신입사원 온보딩 완료 지표로 활용할 수 있습니다."

---

### SLIDE 10 — EmailAgent (3:45~4:25)
> "EmailAgent입니다. 초안 작성부터 수정, 검토, 예외 처리까지 한 흐름으로 지원합니다. '미국 바이어 제안 메일 작성'을 입력하면 거래 조건이 반영된 초안이 생성되고, '영어로 더 공손하게'처럼 짧게 요청해도 같은 맥락에서 즉시 수정됩니다. 검토 시에는 FOV 같은 잘못된 인코텀즈를 자동 탐지하고 단위 혼용도 잡아냅니다. 본문이 없으면 추가 정보를 먼저 요청해 오검토를 방지합니다. 확장성으로는 Gmail MCP 연결해 검토 후 실제 발송까지 연결 가능합니다."

---

### SLIDE 11 — RiskManagingAgent (4:25~5:05)
> "RiskManagingAgent입니다. 자동 응답기가 아닌 실무 현장의 선배 역할을 수행합니다. '선적 지연'이라는 리스크 징후가 감지되면 상황 파악 모드로 전환하고, 계약 금액이나 피해 상황을 대화로 유도하는 협업형 분석을 진행합니다. 리스크 산출 기준인 영향도와 발생 가능성을 친절히 설명하는 교육적 페르소나도 적용했습니다. 마지막으로 RAG 기반 유사 클레임 사례와 단기·장기 예방 전략이 담긴 보고서를 생성합니다. 확장성으로는 실시간 글로벌 리스크 감지와 사내 ERP 연동을 구상 중입니다."

---

### SLIDE 12 — 기술 스택 + 역할 분담 (5:05~5:20)
> "기술 스택은 FastAPI 백엔드, Upstage Solar LLM과 Embedding, ChromaDB 벡터 DB, React 프론트엔드로 구성됩니다. LangSmith로 에이전트 실행을 트레이싱했습니다."

---

### SLIDE 13 — 평가 (5:20~5:35)
> "평가 방법입니다. EvalTool이 5항목을 ChromaDB 원본과 대조해 자동 검증하며, 불합격 시 재시도·대체 생성 루프로 합격 5문제를 보장합니다. 예상 품질 지표는 퀴즈 90%, 용어 검증 90%, 단위 검증 95% 수준입니다."

---

### SLIDE 14 — 데모 (5:35~6:45)
> "데모입니다. 첫 번째, 퀴즈 생성 — '인코텀즈 퀴즈 풀고 싶어요' 입력 시 5문제가 생성됩니다. 두 번째, 이메일 검토 — FOV 잘못된 인코텀즈와 단위 혼용을 자동 탐지합니다. 세 번째, 리스크 분석 — 선적 지연 상황을 멀티턴으로 분석해 CRITICAL 보고서를 생성합니다."
> *(영상 재생)*

---

### SLIDE 15 — 마무리 + Q&A (6:45~7:00)
> "정리하면, RAG 기반 3개 전문 에이전트와 EvalTool 자동 검증 루프를 구현했고, 향후 개인화 학습·Gmail 연동·실시간 리스크 감지로 발전시킬 계획입니다. 이상입니다. 감사합니다."

---

> **총 발표 시간**: 7분
> **총 슬라이드**: 15장
> **폰트**: Noto Sans KR 전체 통일
> **다이어그램**: 기획서 Mermaid 다이어그램 캡처 활용 (SLIDE 05, 06, 07)
